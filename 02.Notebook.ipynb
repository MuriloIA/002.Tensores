{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "144f5198",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# <center>Introdu√ß√£o aos Tensores com PyTorch 2.0</center>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92537cbf",
   "metadata": {},
   "source": [
    "## 1. Introdu√ß√£o üìñ\n",
    "\n",
    "<p style='text-align: justify;'>Bem-vindo a este Jupyter Notebook, onde exploraremos o conceito fundamental do PyTorch 2.0 - os tensores.</p>\n",
    "\n",
    "<p style='text-align: justify;'>O <a href=\"https://pytorch.org/get-started/pytorch-2.0/\" target=\"_blank\">PyTorch</a> √© uma biblioteca de aprendizado de m√°quina de c√≥digo aberto para Python, desenvolvida principalmente pela equipe de pesquisa de intelig√™ncia artificial do <a href=\"https://web.facebook.com/?_rdc=1&_rdr\" target=\"_blank\">Facebook</a>. √â usado para aplica√ß√µes como processamento de linguagem natural e foi projetado para permitir a computa√ß√£o eficiente de tensores com acelera√ß√£o de GPU.</p>\n",
    "\n",
    "<p style='text-align: justify;'>Um tensor √© uma generaliza√ß√£o de vetores e matrizes para um n√∫mero maior de dimens√µes e √© uma entidade matem√°tica muito importante no aprendizado profundo. No PyTorch, tudo √© um tensor. Seja uma imagem, um vetor de recursos, um conjunto de par√¢metros de modelo, todos s√£o representados como tensores.</p>\n",
    "\n",
    "<p style='text-align: justify;'>Neste notebook, vamos mergulhar fundo no mundo dos tensores. Vamos come√ßar com a cria√ß√£o de tensores, entender suas propriedades e opera√ß√µes, e ver como eles s√£o usados no PyTorch para construir modelos de aprendizado profundo.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3888ed33",
   "metadata": {},
   "source": [
    "# 2. FERRAMENTAS UTILIZADAS üõ†\n",
    "\n",
    "### 2.1 Carga de Pacotes Python\n",
    "\n",
    "Este Jupyter Notebook utiliza v√°rias bibliotecas Python, cada uma com um prop√≥sito espec√≠fico:\n",
    "\n",
    "<ol>\n",
    "  <li><strong>os</strong>: <code>Interage com o sistema operacional, permitindo a manipula√ß√£o de arquivos e diret√≥rios.</code></li>\n",
    "  <li><strong>torch</strong>: <code>PyTorch √© usado para aprendizado profundo.</code></li>\n",
    "  <li><strong>warnings</strong>: <code>Emite mensagens de aviso ao usu√°rio.</code></li>\n",
    "  <li><strong>math e numpy</strong>: <code>Realizam opera√ß√µes matem√°ticas.</code></li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ffa0c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch\n",
    "import torch\n",
    "\n",
    "# Ambiente de Desenvolvimento\n",
    "import os \n",
    "import warnings\n",
    "\n",
    "# Matem√°tica\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c0f8bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignorando avisos desnecess√°rios\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecc7933",
   "metadata": {},
   "source": [
    "### 2.2 Checando Vers√µes dos Pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef19f470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--= VERS√ïES DOS PACOTES UTILIZADOS =--\n",
      "  - Numpy: 1.26.0\n",
      "  - Pytorch: 2.0.1+cu117\n",
      "--= ------------------------------ =--\n"
     ]
    }
   ],
   "source": [
    "print(\"--= VERS√ïES DOS PACOTES UTILIZADOS =--\")\n",
    "print(f\"  - Numpy: {np.__version__}\")\n",
    "print(f\"  - Pytorch: {torch.__version__}\")\n",
    "print(\"--= ------------------------------ =--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5c93d6",
   "metadata": {},
   "source": [
    "### 2.3 Reprodutibilidade dos Experimentos\n",
    "\n",
    "<p style='text-align: justify;'>A fun√ß√£o `set_seed` √© usada para definir a semente para geradores de n√∫meros aleat√≥rios no NumPy e PyTorch. Isso √© √∫til para garantir que os experimentos sejam reproduz√≠veis, ou seja, que os mesmos resultados sejam obtidos sempre que o c√≥digo for executado com a mesma semente.</p>\n",
    "\n",
    "Aqui est√£o as funcionalidades de cada parte do c√≥digo:\n",
    "\n",
    "<ol>\n",
    "  <li><code>torch.manual_seed(seed)</code>: Define a semente para o gerador de n√∫meros aleat√≥rios do PyTorch para a CPU.</li>\n",
    "  <li><code>os.environ['PYTHONHASHSEED'] = str(seed)</code>: Define a semente para as fun√ß√µes hash do Python.</li>\n",
    "  <li><code>if torch.cuda.is_available()</code>: Verifica se uma GPU est√° dispon√≠vel.</li>\n",
    "  <li><code>torch.cuda.manual_seed_all(seed)</code>: Define a semente para todas as GPUs dispon√≠veis.</li>\n",
    "  <li><code>torch.backends.cudnn.deterministic = True</code>: Garante que o backend cuDNN use apenas algoritmos determin√≠sticos.</li>\n",
    "  <li><code>torch.backends.cudnn.benchmark = False</code>: Desativa o uso de um algoritmo de convolu√ß√£o heur√≠stico.</li>\n",
    "</ol>\n",
    "\n",
    "A chamada `set_seed(seed=1996)` no final do bloco de c√≥digo √© usada para aplicar a semente definida √† fun√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f7fc16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=1996):\n",
    "    \n",
    "    # CPU\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    \n",
    "    # GPU\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        \n",
    "# Chamando a fun√ß√£o set_seed()\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a0ba71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispositivo usado: cpu\n"
     ]
    }
   ],
   "source": [
    "# Dispositivo usado\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Dispositivo usado: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815ee8a2",
   "metadata": {},
   "source": [
    "## 3. Tensores com Pytorch üßÆ\n",
    "\n",
    "### 3.1 Tensores com Valores Fixos\n",
    "\n",
    "No PyTorch, `torch.zeros`, `torch.ones` e `torch.full` s√£o fun√ß√µes que retornam tensores preenchidos com valores fixos.\n",
    "\n",
    "<ol>\n",
    "  <li>\n",
    "    <code>torch.zeros(*size, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) ‚Üí Tensor</code>: Este m√©todo retorna um tensor preenchido com o valor escalar 0, com a forma definida pelo argumento vari√°vel <code>size</code>.\n",
    "  </li>\n",
    "  <li>\n",
    "    <code>torch.ones(*size, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) ‚Üí Tensor</code>: Este m√©todo retorna um tensor preenchido com o valor escalar 1, com a forma definida pelo argumento vari√°vel <code>size</code>.\n",
    "  </li>\n",
    "  <li>\n",
    "    <code>torch.full(size, fill_value, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) ‚Üí Tensor</code>: Este m√©todo retorna um tensor de tamanho <code>size</code> preenchido com <code>fill_value</code>.\n",
    "  </li>\n",
    "</ol>\n",
    "\n",
    "Essas fun√ß√µes s√£o √∫teis para inicializar tensores quando voc√™ sabe a forma do tensor, mas n√£o precisa dos valores iniciais. Al√©m disso, elas tamb√©m s√£o √∫teis para criar m√°scaras ou outros tensores auxiliares em seus c√°lculos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf87f26b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando um tensor de zeros\n",
    "torch.zeros(size=(4, 3), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06b92a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando um tensor de uns\n",
    "torch.ones(size=(3, 4), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "124cff7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7., 7., 7., 7., 7., 7., 7.],\n",
       "        [7., 7., 7., 7., 7., 7., 7.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando um tensor de setes\n",
    "torch.full(size=(2, 7), fill_value=7, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fa23d8",
   "metadata": {},
   "source": [
    "### 3.2 Transformando Listas e Arrays Numpy em Tensores e Vice-versa\n",
    "\n",
    "A capacidade de transformar arrays Numpy e listas em tensores e vice-versa √© extremamente √∫til em muitos cen√°rios. Aqui est√£o alguns exemplos:\n",
    "\n",
    "<ol>\n",
    "  <li>\n",
    "    <strong>Compatibilidade com bibliotecas existentes</strong>: Muitas bibliotecas de ci√™ncia de dados e aprendizado de m√°quina, como NumPy, Pandas e Scikit-learn, usam arrays NumPy como estrutura de dados principal. Ser capaz de converter facilmente entre tensores PyTorch e arrays NumPy permite que voc√™ integre c√≥digo PyTorch com c√≥digo que usa essas bibliotecas.\n",
    "  </li>\n",
    "  <li>\n",
    "    <strong>Efici√™ncia de mem√≥ria</strong>: Ao converter arrays NumPy em tensores PyTorch, o PyTorch tentar√° usar a mesma mem√≥ria subjacente que o array NumPy, se poss√≠vel. Isso pode resultar em economia de mem√≥ria significativa se voc√™ estiver trabalhando com grandes arrays NumPy que voc√™ deseja converter em tensores.\n",
    "  </li>\n",
    "  <li>\n",
    "    <strong>Aproveitando recursos do PyTorch</strong>: O PyTorch oferece muitos recursos poderosos, como diferencia√ß√£o autom√°tica e acelera√ß√£o de GPU, que n√£o est√£o dispon√≠veis no NumPy. Ao converter arrays NumPy em tensores PyTorch, voc√™ pode aproveitar esses recursos.\n",
    "  </li>\n",
    "  <li>\n",
    "    <strong>Manipula√ß√£o de dados</strong>: As listas s√£o uma estrutura de dados fundamental em Python e s√£o usadas para armazenar cole√ß√µes de itens. Ser capaz de converter facilmente entre listas e tensores permite que voc√™ manipule e processe esses dados usando as opera√ß√µes de tensor do PyTorch.\n",
    "  </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e023ad8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma lista Python\n",
    "lista_python = [1, 2, 3, 4]\n",
    "\n",
    "# Criando um Array Numpy\n",
    "array_numpy = np.array([1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3b33807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lista Python para tensor: tensor([1., 2., 3., 4.])\n",
      "Array Numpy para tensor: tensor([1., 2., 3., 4.])\n"
     ]
    }
   ],
   "source": [
    "# Converte uma lista para tensor\n",
    "print(f\"Lista Python para tensor: {torch.Tensor(lista_python)}\")\n",
    "\n",
    "# Converte um array numpy para tensor\n",
    "print(f\"Array Numpy para tensor: {torch.Tensor(array_numpy)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7dc8b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor para lista Python: [1.0, 2.0, 3.0, 4.0]\n",
      "Tensor para array Numpy: [1. 2. 3. 4.]\n"
     ]
    }
   ],
   "source": [
    "# Converte um tensor para uma lista Python\n",
    "print(f\"Tensor para lista Python: {torch.Tensor(lista_python).tolist()}\")\n",
    "\n",
    "# Converte um tensor em um Array Numpy\n",
    "print(f\"Tensor para array Numpy: {torch.Tensor(array_numpy).numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78f2ab3",
   "metadata": {},
   "source": [
    "### 3.3 Tensores aleat√≥rios\n",
    "\n",
    "Os tensores aleat√≥rios s√£o uma parte importante do PyTorch e s√£o usados em muitos cen√°rios, como a inicializa√ß√£o de pesos em redes neurais. Aqui est√£o algumas fun√ß√µes que voc√™ pode usar para criar tensores aleat√≥rios no PyTorch:\n",
    "\n",
    "<ol>\n",
    "  <li>\n",
    "    <code>torch.rand(*size, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) ‚Üí Tensor</code>: Esta fun√ß√£o retorna um tensor preenchido com n√∫meros aleat√≥rios uniformemente distribu√≠dos entre 0 e 1.\n",
    "  </li>\n",
    "  <li>\n",
    "    <code>torch.randn(*size, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) ‚Üí Tensor</code>: Esta fun√ß√£o retorna um tensor preenchido com n√∫meros aleat√≥rios normalmente distribu√≠dos com m√©dia 0 e vari√¢ncia 1.\n",
    "  </li>\n",
    "  <li>\n",
    "    <code>torch.randint(low=0, high, size, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) ‚Üí Tensor</code>: Esta fun√ß√£o retorna um tensor preenchido com inteiros aleat√≥rios gerados uniformemente entre <code>low</code> (inclusive) e <code>high</code> (exclusivo).\n",
    "  </li>\n",
    "</ol>\n",
    "\n",
    "Essas fun√ß√µes s√£o √∫teis quando voc√™ precisa de um tensor com elementos aleat√≥rios. Por exemplo, voc√™ pode usar `torch.rand` para inicializar os pesos de uma rede neural com valores aleat√≥rios pequenos, o que √© uma pr√°tica comum no aprendizado profundo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdeba206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5421, 0.0359, 0.8337, 0.6938],\n",
       "        [0.2609, 0.2559, 0.3787, 0.4453],\n",
       "        [0.9004, 0.5096, 0.5480, 0.7183],\n",
       "        [0.7592, 0.5139, 0.7727, 0.4157]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando um tensor com valores aleat√≥rios preenchido com n√∫meros uniformemente distribu√≠dos entre 0 e 1\n",
    "torch.rand(size=(4, 4), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d26519f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6538,  0.6724, -0.5107,  0.6322, -1.6815],\n",
       "        [ 0.7980, -1.2627,  1.0787, -0.4232, -1.8421],\n",
       "        [-0.5638, -1.4728,  0.6927, -0.7499, -0.9444],\n",
       "        [ 0.3950, -1.1509, -1.2043,  0.5978, -0.1458]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando um tensor preenchido com n√∫meros aleat√≥rios normalmente distribu√≠dos com m√©dia 0 e vari√¢ncia 1\n",
    "torch.randn(size=(4, 5), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ee36c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 2, 1, 9, 5],\n",
       "        [8, 4, 6, 6, 2],\n",
       "        [9, 5, 0, 1, 3],\n",
       "        [8, 9, 1, 4, 6]], dtype=torch.int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando um tensor preenchido com inteiros aleat√≥rios gerados uniformemente\n",
    "torch.randint(low=0, high=10, size=(4, 5), dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4aba789",
   "metadata": {},
   "source": [
    "### 3.4 Formas de Tensores\n",
    "\n",
    "A ‚Äúforma‚Äù de um tensor se refere √†s dimens√µes do tensor. Por exemplo, um tensor 1D (ou vetor) com comprimento `n` ter√° a forma `(n,)`. Um tensor 2D (ou matriz) com `m` linhas e `n` colunas ter√° a forma `(m, n)`. Da mesma forma, um tensor 3D ter√° a forma `(l, m, n)` e assim por diante.\n",
    "\n",
    "Aqui est√£o algumas maneiras de criar tensores com formas espec√≠ficas no PyTorch:\n",
    "\n",
    "<ol>\n",
    "  <li>\n",
    "    <code>torch.empty(*size, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) ‚Üí Tensor</code>: Esta fun√ß√£o retorna um tensor preenchido com dados n√£o inicializados. A forma do tensor √© definida pelo argumento vari√°vel <code>size</code>.\n",
    "  </li>\n",
    "  <li>\n",
    "    <code>torch.empty_like(input, *, dtype=None, layout=None, device=None, requires_grad=False) ‚Üí Tensor</code>: Esta fun√ß√£o retorna um tensor n√£o inicializado com o mesmo tamanho que o <code>input</code>. √â equivalente a <code>torch.empty(input.size(), dtype=input.dtype, layout=input.layout, device=input.device)</code>.\n",
    "  </li>\n",
    "  <li>\n",
    "    <code>torch.zeros_like(input, *, dtype=None, layout=None, device=None, requires_grad=False) ‚Üí Tensor</code>: Esta fun√ß√£o retorna um tensor preenchido com o valor escalar 0, com o mesmo tamanho que o <code>input</code>. √â equivalente a <code>torch.zeros(input.size(), dtype=input.dtype, layout=input.layout, device=input.device)</code>.\n",
    "  </li>\n",
    "  <li>\n",
    "    <code>torch.ones_like(input, *, dtype=None, layout=None, device=None, requires_grad=False) ‚Üí Tensor</code>: Esta fun√ß√£o retorna um tensor preenchido com o valor escalar 1, com o mesmo tamanho que o <code>input</code>. √â equivalente a <code>torch.ones(input.size(), dtype=input.dtype, layout=input.layout, device=input.device)</code>.\n",
    "  </li>\n",
    "  <li>\n",
    "    <code>torch.rand_like(input, *, dtype=None, layout=None, device=None, requires_grad=False) ‚Üí Tensor</code>: Esta fun√ß√£o retorna um tensor preenchido com n√∫meros aleat√≥rios de uma distribui√ß√£o uniforme no intervalo [0, 1), com o mesmo tamanho que o <code>input</code>. √â equivalente a <code>torch.rand(input.size(), dtype=input.dtype, layout=input.layout, device=input.device)</code>.\n",
    "  </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e05278ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor\n",
      "tensor([[ 2.7380e-35,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.7358e-35],\n",
      "        [ 0.0000e+00,  2.4726e-36,  0.0000e+00, -9.9467e-14,  4.5663e-41]])\n",
      "Dimens√µes:\n",
      "torch.Size([2, 5])\n"
     ]
    }
   ],
   "source": [
    "# Tensor preenchido com dados n√£o inicializados/dados da mem√≥ria\n",
    "tensor_empty = torch.empty(size=(2, 5))\n",
    "\n",
    "# Imprimindo o tensor e suas dimens√µes\n",
    "print(f\"Tensor\\n{tensor_empty}\\nDimens√µes:\\n{tensor_empty.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "108cf881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.8374e-11,  4.5663e-41,  2.7373e-35,  0.0000e+00,  1.4013e-45],\n",
       "        [ 0.0000e+00,  2.7341e-35,  0.0000e+00,  0.0000e+00,  0.0000e+00]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor n√£o inicializado equivalente √† torch.empty(input.size())\n",
    "torch.empty_like(tensor_empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46f60d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor preenchido com o valor escalar 0, equivalente a torch.zeros(input.size())\n",
    "torch.zeros_like(tensor_empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff67734a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor preenchido com o valor escalar 1, equivalente a torch.ones(input.size())\n",
    "torch.ones_like(tensor_empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2478842e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6451, 0.9702, 0.4817, 0.0741, 0.5134],\n",
       "        [0.7750, 0.7207, 0.1815, 0.3376, 0.6172]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor preenchido com valores aleat√≥rios uniformemente distribuido entre [0, 1].\n",
    "# Equivalente a torch.rand(input.size())\n",
    "torch.rand_like(tensor_empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "089c7a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7, 7, 7, 7, 7],\n",
       "        [7, 7, 7, 7, 7]], dtype=torch.int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor preenchido com um valor pr√©-definido, equivalente a torch.full(input.size())\n",
    "torch.full_like(tensor_empty, fill_value=7, dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9ea21c",
   "metadata": {},
   "source": [
    "### 3.5 Tipos de dados tensores\n",
    "\n",
    "Os tensores do PyTorch s√£o matrizes multidimensionais que cont√™m elementos de um √∫nico tipo de dado. O PyTorch define 10 tipos de tensores com variantes de CPU e GPU. Aqui est√£o os tipos de dados de tensor dispon√≠veis no PyTorch 2.0:\n",
    "\n",
    "<ul>\n",
    "  <li><strong>32-bit floating point</strong>: <code>torch.float32</code> ou <code>torch.float</code></li>\n",
    "  <li><strong>64-bit floating point</strong>: <code>torch.float64</code> ou <code>torch.double</code></li>\n",
    "  <li><strong>16-bit floating point [1]</strong>: <code>torch.float16</code> ou <code>torch.half</code></li>\n",
    "  <li><strong>16-bit floating point [2]</strong>: <code>torch.bfloat16</code></li>\n",
    "  <li><strong>32-bit complex</strong>: <code>torch.complex32</code> ou <code>torch.chalf</code></li>\n",
    "  <li><strong>64-bit complex</strong>: <code>torch.complex64</code> ou <code>torch.cfloat</code></li>\n",
    "  <li><strong>128-bit complex</strong>: <code>torch.complex128</code> ou <code>torch.cdouble</code></li>\n",
    "  <li><strong>8-bit integer (unsigned)</strong>: <code>torch.uint8</code></li>\n",
    "  <li><strong>8-bit integer (signed)</strong>: <code>torch.int8</code></li>\n",
    "  <li><strong>16-bit integer (signed)</strong>: <code>torch.int16</code> ou <code>torch.short</code></li>\n",
    "  <li><strong>32-bit integer (signed)</strong>: <code>torch.int32</code> ou <code>torch.int</code></li>\n",
    "  <li><strong>64-bit integer (signed)</strong>: <code>torch.int64</code> ou <code>torch.long</code></li>\n",
    "  <li><strong>Boolean</strong>: <code>torch.bool</code></li>\n",
    "</ul>\n",
    "\n",
    "Cada tipo de tensor tem suas pr√≥prias caracter√≠sticas e usos. Veja alguns exemplos de cria√ß√£o de tensores abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4273d8da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[31, 20, 34, 20, 41],\n",
       "         [ 7, 87,  4, 30, 78],\n",
       "         [16, 73,  5, 99, 69],\n",
       "         [50, 84, 95, 83, 44],\n",
       "         [54, 83, 76,  6, 30]],\n",
       "\n",
       "        [[89, 25,  3, 50, 66],\n",
       "         [33, 97, 85, 32, 74],\n",
       "         [25, 83, 60,  8, 27],\n",
       "         [59, 43, 26,  8, 19],\n",
       "         [86, 55,  1, 51, 15]]], dtype=torch.int16)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor int16\n",
    "torch.randint(low=0, high=100, size=(2, 5, 5), dtype=torch.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c48382d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.9415,  1.1322, -1.0530,  1.1068, -0.0437],\n",
       "         [-0.2157, -0.2562,  1.1820, -0.2341,  0.7723],\n",
       "         [ 0.0607, -1.3471,  1.6745,  1.7941, -0.4955],\n",
       "         [ 1.2411, -0.3938,  2.1914, -1.3212, -0.5561],\n",
       "         [ 0.5730,  0.1772, -1.9993,  1.1892, -1.4911]],\n",
       "\n",
       "        [[-0.2772,  0.0374,  0.2431,  0.1902, -0.5840],\n",
       "         [ 0.1629,  1.5833, -0.1184,  0.5443,  0.3447],\n",
       "         [-0.7040, -1.3075, -0.6274,  0.5751, -1.4587],\n",
       "         [ 0.5204, -0.2349, -2.3035,  1.3408,  1.2252],\n",
       "         [-0.5836,  0.2966,  0.5345, -0.4606,  0.2670]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor float32\n",
    "torch.randn(size=(2, 5, 5), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f79fce",
   "metadata": {},
   "source": [
    "## 4. Matem√°tica e l√≥gica com tensores PyTorch üí°\n",
    "\n",
    "Os tensores do PyTorch suportam uma ampla variedade de opera√ß√µes matem√°ticas e l√≥gicas. Aqui est√£o alguns exemplos:\n",
    "\n",
    "<ul>\n",
    "  <li><strong>Opera√ß√µes aritm√©ticas</strong>: As opera√ß√µes aritm√©ticas b√°sicas como adi√ß√£o, subtra√ß√£o, multiplica√ß√£o e divis√£o podem ser realizadas em tensores. Al√©m disso, o PyTorch tamb√©m suporta opera√ß√µes mais complexas como raiz quadrada, exponencia√ß√£o, logaritmo, etc.</li>\n",
    "  <li><strong>Opera√ß√µes l√≥gicas</strong>: O PyTorch suporta opera√ß√µes l√≥gicas como AND, OR e XOR em tensores booleanos. Por exemplo, a fun√ß√£o <code>torch.logical_and</code> calcula o AND l√≥gico elemento a elemento dos tensores de entrada. Os zeros s√£o tratados como False e os n√£o zeros s√£o tratados como True.</li>\n",
    "  <li><strong>Indexa√ß√£o, fatiamento, jun√ß√£o, muta√ß√£o</strong>: O PyTorch suporta v√°rias opera√ß√µes para manipular tensores, incluindo indexa√ß√£o, fatiamento, jun√ß√£o (por exemplo, <code>torch.cat</code>), e muta√ß√£o (por exemplo, <code>torch.transpose</code>). Essas opera√ß√µes permitem reorganizar, redimensionar, e modificar tensores de v√°rias maneiras.</li>\n",
    "  <li><strong>Fun√ß√µes matem√°ticas</strong>: O PyTorch tamb√©m inclui uma ampla gama de fun√ß√µes matem√°ticas que podem ser aplicadas a tensores, como fun√ß√µes trigonom√©tricas, fun√ß√µes exponenciais e logar√≠tmicas, etc.</li>\n",
    "</ul>\n",
    "\n",
    "Essas opera√ß√µes podem ser usadas para realizar uma ampla variedade de c√°lculos e s√£o fundamentais para muitos algoritmos de aprendizado de m√°quina.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777daf1c",
   "metadata": {},
   "source": [
    "### 4.1 Opera√ß√µes Aritm√©ticas\n",
    "\n",
    "As opera√ß√µes aritm√©ticas s√£o fundamentais quando trabalhamos com tensores no PyTorch. Aqui est√£o algumas das opera√ß√µes mais comuns:\n",
    "\n",
    "<ol>\n",
    "  <li>\n",
    "    <strong>Adi√ß√£o</strong>: Voc√™ pode adicionar dois tensores usando o operador <code>+</code> ou a fun√ß√£o <code>torch.add()</code>. Por exemplo, se voc√™ tem dois tensores <code>a</code> e <code>b</code>, voc√™ pode adicionar os dois usando <code>a + b</code> ou <code>torch.add(a, b)</code>.\n",
    "  </li>\n",
    "  <li>\n",
    "    <strong>Subtra√ß√£o</strong>: A subtra√ß√£o de tensores pode ser realizada usando o operador <code>-</code> ou a fun√ß√£o <code>torch.sub()</code>. Por exemplo, <code>a - b</code> ou <code>torch.sub(a, b)</code>.\n",
    "  </li>\n",
    "  <li>\n",
    "    <strong>Multiplica√ß√£o</strong>: A multiplica√ß√£o de tensores pode ser feita de v√°rias maneiras, dependendo do que voc√™ precisa. A multiplica√ß√£o elemento a elemento pode ser feita usando <code>a * b</code> ou <code>torch.mul(a, b)</code>. A multiplica√ß√£o de matrizes pode ser realizada usando <code>torch.matmul(a, b)</code>.\n",
    "  </li>\n",
    "  <li>\n",
    "    <strong>Divis√£o</strong>: A divis√£o de tensores pode ser realizada usando o operador <code>/</code> ou a fun√ß√£o <code>torch.div()</code>. Por exemplo, <code>a / b</code> ou <code>torch.div(a, b)</code>.\n",
    "  </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1446ea15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adi√ß√£o: tensor([[2., 2., 2., 2.]])\n",
      "Subtra√ß√£o: tensor([[0., 0., 0., 0.]])\n",
      "Multiplica√ß√£o: tensor([[0.5000, 0.5000, 0.5000, 0.5000]])\n",
      "Exponencia√ß√£o: tensor([[0.2000, 0.2000, 0.2000, 0.2000]])\n"
     ]
    }
   ],
   "source": [
    "# Opera√ß√µes aritm√©ticas de um tensor por escalar\n",
    "print(f'Adi√ß√£o: {torch.ones(size=(1, 4)) + 1}')\n",
    "print(f'Subtra√ß√£o: {torch.ones(size=(1, 4)) - 1}')\n",
    "print(f'Multiplica√ß√£o: {torch.ones(size=(1, 4)) / 2}')\n",
    "print(f'Exponencia√ß√£o: {torch.ones(size=(1, 4)) ** 1/5}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96e24105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adi√ß√£o: tensor([[4.5000, 4.5000, 4.5000, 4.5000, 4.5000]])+tensor([[-0.8075,  0.4227,  1.2055, -1.4151, -1.9007]])=tensor([[3.6925, 4.9227, 5.7055, 3.0849, 2.5993]])\n",
      "\n",
      "Subtra√ß√£o: tensor([[4.5000, 4.5000, 4.5000, 4.5000, 4.5000]])+tensor([[-0.8075,  0.4227,  1.2055, -1.4151, -1.9007]])=tensor([[-3.6340,  1.9023,  5.4249, -6.3679, -8.5531]])\n",
      "\n",
      "Multiplica√ß√£o: tensor([[4.5000, 4.5000, 4.5000, 4.5000, 4.5000]])/tensor([[-0.8075,  0.4227,  1.2055, -1.4151, -1.9007]])=tensor([[-5.5724, 10.6449,  3.7328, -3.1800, -2.3676]])\n",
      "\n",
      "Exponencia√ß√£o: tensor([[4.5000, 4.5000, 4.5000, 4.5000, 4.5000]])^tensor([[-0.8075,  0.4227,  1.2055, -1.4151, -1.9007]])=tensor([[0.2968, 1.8886, 6.1302, 0.1190, 0.0573]])\n"
     ]
    }
   ],
   "source": [
    "# Criando tensores\n",
    "t1 = torch.full(size=(1, 5), fill_value=4.5, dtype=torch.float32)\n",
    "t2 = torch.randn_like(t1)\n",
    "\n",
    "# Opera√ß√µes artim√©ticas entre tensores\n",
    "print(f'Adi√ß√£o: {t1}+{t2}={t1 + t2}\\n')\n",
    "print(f'Subtra√ß√£o: {t1}+{t2}={t1*t2}\\n')\n",
    "print(f'Multiplica√ß√£o: {t1}/{t2}={t1/t2}\\n')\n",
    "print(f'Exponencia√ß√£o: {t1}^{t2}={t1**t2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca84d0c1",
   "metadata": {},
   "source": [
    "### 4.2 Manipulando formas de tensor\n",
    "\n",
    "Trabalhar com tensores em PyTorch muitas vezes envolve manipular suas formas. Aqui est√£o algumas das opera√ß√µes mais comuns:\n",
    "\n",
    "<ol>\n",
    "  <li>\n",
    "    <strong>Reshape</strong>: A fun√ß√£o <code>torch.reshape()</code> pode ser usada para reorganizar os elementos de um tensor para se ajustar a uma determinada forma. Por exemplo, se voc√™ tem um tensor de forma <code>(4, 2)</code> e deseja reorganiz√°-lo para a forma <code>(2, 4)</code>, voc√™ pode usar <code>torch.reshape(tensor, (2, 4))</code>.\n",
    "  </li>\n",
    "  <li>\n",
    "    <strong>Squeeze e Unsqueeze</strong>: <code>torch.squeeze()</code> remove as dimens√µes de tamanho 1 do tensor, enquanto <code>torch.unsqueeze()</code> adiciona uma dimens√£o extra de tamanho 1. Isso √© √∫til para adicionar ou remover dimens√µes que s√£o necess√°rias para certas opera√ß√µes.\n",
    "  </li>\n",
    "  <li>\n",
    "    <strong>Flatten</strong>: <code>torch.flatten()</code> √© usado para transformar o tensor em um tensor 1D. Isso √© √∫til quando voc√™ quer transformar um tensor multidimensional em um vetor.\n",
    "  </li>\n",
    "  <li>\n",
    "    <strong>Permute e Transpose</strong>: <code>torch.permute()</code> permite reordenar as dimens√µes de um tensor de qualquer maneira que voc√™ quiser. <code>torch.transpose()</code> √© um caso especial disso, onde duas dimens√µes s√£o trocadas. Isso √© comumente usado para trocar as dimens√µes de altura e largura em imagens.\n",
    "  </li>\n",
    "  <li>\n",
    "    <strong>Size e Shape</strong>: <code>tensor.size()</code> e <code>tensor.shape</code> retornam o tamanho do tensor. <code>tensor.numel()</code> retorna o n√∫mero total de elementos no tensor.\n",
    "  </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "479d49e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.5634, -1.2311, -0.8583],\n",
      "        [ 1.1428,  1.3181, -0.1957],\n",
      "        [-0.6026,  0.1019, -0.1568],\n",
      "        [ 0.3462, -0.7328,  1.1331]])\n"
     ]
    }
   ],
   "source": [
    "# Criando Tensor\n",
    "t = torch.randn(size=(4, 3), dtype=torch.float32)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b6fc256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.5634, -1.2311, -0.8583],\n",
       "         [ 1.1428,  1.3181, -0.1957],\n",
       "         [-0.6026,  0.1019, -0.1568],\n",
       "         [ 0.3462, -0.7328,  1.1331]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adiciona uma dimens√£o extra de tamanho 1\n",
    "t.unsqueeze(dim=(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f088986f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  torch.Size([4, 3])\n",
      "unsqueeze: torch.Size([1, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "# Dimens√µes do tensor\n",
    "print(\"Original: \",t.shape)\n",
    "print(\"unsqueeze:\", t.unsqueeze(dim=(0)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f13ec9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.5634, -1.2311, -0.8583],\n",
       "         [ 1.1428,  1.3181, -0.1957],\n",
       "         [-0.6026,  0.1019, -0.1568],\n",
       "         [ 0.3462, -0.7328,  1.1331]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usando reshape\n",
    "t.reshape((1, 4, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "71c3bbd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.5634, -1.2311, -0.8583,  1.1428,  1.3181, -0.1957, -0.6026,  0.1019,\n",
       "        -0.1568,  0.3462, -0.7328,  1.1331])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Achatando um tensor nD para 1D\n",
    "t.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09dee9d",
   "metadata": {},
   "source": [
    "### 4.3 Fatiamento/Slicing de Tensores\n",
    "\n",
    "O fatiamento, ou slicing, √© uma t√©cnica essencial ao trabalhar com tensores no PyTorch. Esta opera√ß√£o permite acessar e manipular partes espec√≠ficas de um tensor de forma eficiente e intuitiva.\n",
    "\n",
    "Semelhante √†s listas e arrays em Python, o PyTorch permite o fatiamento de tensores. Por exemplo, em um tensor bidimensional (uma matriz), √© poss√≠vel acessar um elemento espec√≠fico fornecendo os √≠ndices da linha e da coluna. Al√©m disso, √© poss√≠vel acessar uma linha ou coluna inteira de uma matriz usando a t√©cnica de fatiamento.\n",
    "\n",
    "O fatiamento √© uma ferramenta poderosa que facilita a manipula√ß√£o e o acesso aos dados dos tensores. Com a pr√°tica, voc√™ descobrir√° muitos usos para o fatiamento ao trabalhar com tensores no PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "430dc359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3, 9, 5, 3, 5],\n",
      "        [0, 6, 7, 7, 9],\n",
      "        [4, 4, 0, 2, 7],\n",
      "        [9, 8, 2, 1, 2],\n",
      "        [1, 4, 9, 7, 5],\n",
      "        [6, 9, 0, 4, 1],\n",
      "        [7, 7, 6, 5, 2]])\n"
     ]
    }
   ],
   "source": [
    "# Cria tensor de inteiros uniformemente distribu√≠dos\n",
    "tensor_int = torch.randint(low=0, high=10, size=(7, 5))\n",
    "print(tensor_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f86ad61b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9, 1, 5, 3, 8])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Primeira linha\n",
    "tensor_int[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6893ebfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 0, 4, 9, 1, 6, 7])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Primeira coluna\n",
    "tensor_int[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed1a7605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 9, 5, 3, 5],\n",
       "        [0, 6, 7, 7, 9]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As duas primeiras linhas\n",
    "tensor_int[0:2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "88879ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 9],\n",
       "        [0, 6],\n",
       "        [4, 4],\n",
       "        [9, 8],\n",
       "        [1, 4],\n",
       "        [6, 9],\n",
       "        [7, 7]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As duas primeiras colunas\n",
    "tensor_int[:,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ea91d571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6, 9, 0, 4, 1],\n",
       "        [7, 7, 6, 5, 2]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As duas √∫ltimas linhas\n",
    "tensor_int[-2:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fe2ee32e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 5],\n",
       "        [7, 9],\n",
       "        [2, 7],\n",
       "        [1, 2],\n",
       "        [7, 5],\n",
       "        [4, 1],\n",
       "        [5, 2]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As duas √∫ltimas colunas\n",
    "tensor_int[:, -2:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
